# Going Deeper프로젝트에서 이론에 해당하는 내용입니다.
### [GD1. 텍스트데이터다루기](https://foul-beechnut-069.notion.site/GD1-fa2a962631b34a77b9e4bfdb006124f4)
  - 1.Preprocessing : 자연어의 노이즈 제거
  - 2.분산표현 : 바나나와 사과의 관계를 어떻게 표현할까?
  - 3.토큰화 : 그녀는? 그녀+는?  
  - 4.토큰화 : 다른 방법들
  - 5.토큰에게 의미를 부여하기
  - 6.마무리
### [GD2.텍스트의 분포로 벡터화 하기](https://foul-beechnut-069.notion.site/GD2-a8aec887008c4ff3b4129734662052ee)
  - 1.단어 빈도를 이용한 벡터화
  - 2.LSA와 LDA
  - 3.텍스트 분포를 이용한 비지도 학습 토크나이저
### [GD3.워드임베딩](https://foul-beechnut-069.notion.site/GD3-7f00360c6d84425cb08a736e2150ff9d)
  - 1.Vectorization
  - 2.원-핫 인코딩 구현해보기
  - 3.워드 임베딩
  - 4.Word2Vec : 분포 가설
  - 5.Word2Vec : CBoW
  - 6.Word2Vec : Skip-gram과 Negative Sampling
  - 7.Word2Vec : 영어 word2vec실습과 OOV문제
  - 8.FastText
  - 9.GloVe(Global Vectors for Word Representation)
### [GD5.Transformer가 나오기까지](https://foul-beechnut-069.notion.site/GD5-Transformer-21bd28eecaa34f0cba83a5e2abd7440a)
  - 1. Attention의 역사
  - 2. Positional Encoding
  - 3. Multi-Head Attention
### [GD6.기계 번역이 걸어온 길](https://foul-beechnut-069.notion.site/GD6-4b6980b12b89490186e965f8bf80f9ae)
  - 1. 번역의 흐름
  - 2. 문장 생성 방식
  - 3. Data Augmentation
  - 4. 성능 평가 지표, BLEU score
  - 5. 챗봇과 번역기
  - 6. 좋은 챗봇이 되려면
