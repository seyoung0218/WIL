## 밑바닥부터 시작하느 딥러닝 2
![](./cover.png)
- [Chapter2. 자연어와 단어의 분산 표현](https://foul-beechnut-069.notion.site/Chapter2-2d43eafacb2a46738588c5f86482684f)
  - 2.1 자연어 처리란
  - 2.2 시소러스
  - 2.3 통계 기반 기법
  - 2.4 통계 기반 기법 개선하기
  - 2.5 정리
- [Chapter3. word2vec](https://foul-beechnut-069.notion.site/Chapter3-word2vec-b017e0a388d6400180351dc3d018bc7b)
  - 3.1 추론 기반 기법과 신경망
  - 3.2 단순한 word2vec
  - 3.3 학습 데이터 준비
  - 3.4 CBOW 모델 구현
  - 3.5 word2vec 보충
  - 3.6 정리
- [Chapter4. word2vec 속도 개선](https://foul-beechnut-069.notion.site/Chapter4-word2vec-4a5e598978384edf8c9312f64d9fac63)
  - 4.1 word2vec 개선 1️⃣
  - 4.2 word2vec 개선 2️⃣
  - 4.3 개선판 word2vec학습
  - 4.4 word2vec 남은 주제
  - 4.5 정리
- [Chapter5. 순환 신경망(RNN)](https://foul-beechnut-069.notion.site/Chapter5-RNN-bb66d19e129a43caba1027ae7a19ae30)
  - 5.1 확률과 언어 모델
  - 5.2 RNN이란
  - 5.3 RNN 구현
  - 5.4 시계열 데이터 처리 계층 구현
  - 5.5 RNNLM 학습과 평가
  - 5.6 정리

## 참고문헌
: https://github.com/WegraLee/deep-learning-from-scratch-2
